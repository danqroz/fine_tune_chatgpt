{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import openai\n",
    "import tiktoken\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "script_dir = os.getcwd()\n",
    "counsel_path = os.path.join(script_dir, \"data\", \"cleaned_counselchat.csv\")\n",
    "chatbot_path = os.path.join(script_dir, \"data\", \"cleaned_chatbot_data.csv\")\n",
    "\n",
    "MAX_TRAIN_SIZE = 700\n",
    "SYS_MSG = \"\"\"You are Regina, a helpful counselor with a lot of empathy.\n",
    "You talk to people who need psychological support and try to alleviate\n",
    "their pain by giving advice without making judgments.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(row):\n",
    "    messages = list()\n",
    "\n",
    "    messages.append({\n",
    "        \"role\": \"system\",\n",
    "        \"content\": SYS_MSG\n",
    "    })\n",
    "\n",
    "    user_msg = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": row[\"questionText\"]\n",
    "    }\n",
    "    assistant_msg = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": row[\"clean_answer\"]\n",
    "    }\n",
    "\n",
    "    messages.extend([user_msg, assistant_msg])\n",
    "    return {\"messages\": messages}\n",
    "\n",
    "df = pd.read_csv(counsel_path)\n",
    "df = df.drop_duplicates(subset=\"questionText\")\n",
    "if len(df) > MAX_TRAIN_SIZE:\n",
    "    df = df.sample(MAX_TRAIN_SIZE)\n",
    "\n",
    "df2 = pd.read_csv(chatbot_path)\n",
    "\n",
    "full_df = pd.concat([df, df2]).sample(frac=1).reset_index(drop=True)\n",
    "df_train = full_df[:-100]\n",
    "df_val = full_df[-100:]\n",
    "\n",
    "\n",
    "\n",
    "training_data = df_train.apply(format_data, axis=1).to_list()\n",
    "validation_data = df_val.apply(format_data, axis=1).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'messages': [{'role': 'system',\n",
       "    'content': 'You are Regina, a helpful counselor with a lot of empathy.\\nYou talk to people who need psychological support and try to alleviate\\ntheir pain by giving advice without making judgments.'},\n",
       "   {'role': 'user',\n",
       "    'content': \"I’ve been on 0.5 mg of Xanax twice a day for the past month. It hasn't been helping me at all, but when I take 1 mg during a big anxiety attack, it calms me down. I was wondering how I can ask my psychologist to up the dose to 1 mg twice a day without her thinking I'm abusing them. I just have very big anxiety attacks. Should I stay on the 0.5mg and deal with the attacks or should I ask to up the dose? I'm afraid she will take me off them and put me on something else.\"},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'In general, Xanax is very short-acting. You mentioned that you are afraid that your medical provider will take you off of the Xanax and put you on something else. If the Xanax is not working well for you, I wonder if something else may work better. What is your reasoning there? Also, sometimes there are medications that you can take in addition to Xanax.In addition to talking with your medical provider about changing the medication, try to track your levels of anxiety on a scale of 1 to 10 throughout the day so you can get a pattern of what is happening. Also consider writing down what is happening before you have anxiety attacks. This may help your medical provider know what medication may be helpful to you or what changes could be made.As far as how to discuss this with your medical provider, I would suggest mentioning the symptom changes you are having (anxiety attacks that are not helped with 0.5mg of Xanax) and ask what they would suggest that might help. If your medical provider suggests taking you off of the Xanax, I would recommend talking about the reasons why you would prefer to stay on the Xanax and what your concerns are about coming off of it. You could also ask whether anything could be combined with Xanax.There are also many other anxiety medications. I have seen lots of people that take more than one medication to lessen anxiety that they are having.I would also consider talking with a therapist (unless the person who is prescribing a medication is also doing therapy with you). Getting more information about your anxiety and how it is affecting you may be greatly helpful to you.'}]},\n",
       " {'messages': [{'role': 'system',\n",
       "    'content': 'You are Regina, a helpful counselor with a lot of empathy.\\nYou talk to people who need psychological support and try to alleviate\\ntheir pain by giving advice without making judgments.'},\n",
       "   {'role': 'user',\n",
       "    'content': 'How do I make myself happy without the people who made me happy? Now that they’re gone, I feel sad. It’s been two months now but I seem to be unable to stay okay and independent.'},\n",
       "   {'role': 'assistant',\n",
       "    'content': \"It sounds like you have been feeling pretty down, since the loss of a relationship, and you're wondering how to be happy by yourself. Intimacy is a very natural human desire and at the same time learning to enjoy ourselves, even when we are alone, can strengthen our ability to lead a satisfying life in and out of relationship. Working with a therapist, you may be able to gain insight into how you show up in your relationships with yourself and others and discover more fulfilling ways to do so.\"}]},\n",
       " {'messages': [{'role': 'system',\n",
       "    'content': 'You are Regina, a helpful counselor with a lot of empathy.\\nYou talk to people who need psychological support and try to alleviate\\ntheir pain by giving advice without making judgments.'},\n",
       "   {'role': 'user',\n",
       "    'content': 'I need answers to my anger, possessiveness, and urges.\\n I am angry all the time. I push people away so much that I actually blow up on people now because they ask me how my day is or was. I have a possessiveness to someone who is not even mine. I have these urges to hurt someone really bad. I want to see them beg for me to stop hurting. I want to hear their agonizing pained-filled voices. What is wrong with me?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'What result are you hoping to get from the behaviors you describe?Maybe start by comparing the results you see yourself receiving from your current interactions, with how you would wish to feel from relating to others.Since you ask, \"what is wrong with me?\", there is a disconnect between what you are doing and what you\\'d like in return.This is true even with imagining doing harm to others.What are you really trying to accomplish for yourself by hurting others?Besides the unethicalness and criminality of this and legal consequences of arrest for such behaviors, what gain which is not evil, do you expect from overpowering and imagining you control another human being?'}]}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token counting functions\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# not exact!\n",
    "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 54, 1000\n",
      "mean / median: 271.76601307189543, 247.0\n",
      "p5 / p95: 60.0, 505.0000000000001\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 2, 879\n",
      "mean / median: 166.03529411764706, 136.0\n",
      "p5 / p95: 7.0, 357.80000000000007\n",
      "\n",
      "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n"
     ]
    }
   ],
   "source": [
    "# Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "\n",
    "for ex in training_data:\n",
    "    messages = ex[\"messages\"]\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "    n_messages.append(len(messages))\n",
    "    convo_lens.append(num_tokens_from_messages(messages))\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "\n",
    "print(\"Num examples missing system message:\", n_missing_system)\n",
    "print(\"Num examples missing user message:\", n_missing_user)\n",
    "print_distribution(n_messages, \"num_messages_per_example\")\n",
    "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "n_too_long = sum(l > 4096 for l in convo_lens)\n",
    "print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has ~207901 tokens that will be charged for during training\n",
      "By default, you'll train for 3 epochs on this dataset\n",
      "By default, you'll be charged for ~623703 tokens\n",
      "With a price of $0.008 / 1K Tokens, the cost should be around: $ 4.989624\n"
     ]
    }
   ],
   "source": [
    "# Pricing and default n_epochs estimate\n",
    "MAX_TOKENS_PER_EXAMPLE = 4096\n",
    "\n",
    "TARGET_EPOCHS = 3\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "COST_PER_1K = 0.008\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(training_data)\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")\n",
    "print(f\"With a price of ${COST_PER_1K} / 1K Tokens, the cost should be around: \\\n",
    "$ {(n_epochs * n_billing_tokens_in_dataset) / 1000 * COST_PER_1K}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_jsonl(data_list: list, path: str) -> None:\n",
    "    with open(path, \"w\") as out:\n",
    "        for ddict in data_list:\n",
    "            jout = json.dumps(ddict) + \"\\n\"\n",
    "            out.write(jout)\n",
    "\n",
    "training_path = os.path.join(script_dir, \"data\", \"tmp_recipe_finetune_training.jsonl\")\n",
    "write_jsonl(training_data, training_path)\n",
    "\n",
    "validation_path = os.path.join(script_dir, \"data\", \"tmp_recipe_finetune_validation.jsonl\")\n",
    "write_jsonl(validation_data, validation_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file ID: file-k5x943rw8eWvrvztLH98KYxy\n",
      "Validation file ID: file-pzQXHAs6Q9MooAjb1DmCNpos\n"
     ]
    }
   ],
   "source": [
    "training_response = openai.File.create(\n",
    "    file=open(training_path, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "training_file_id = training_response[\"id\"]\n",
    "\n",
    "validation_response = openai.File.create(\n",
    "    file=open(validation_path, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "validation_file_id = validation_response[\"id\"]\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.FineTuningJob.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    suffix=\"counselor-test2\",\n",
    ")\n",
    "\n",
    "job_id = response[\"id\"]\n",
    "\n",
    "print(\"Job ID:\", response[\"id\"])\n",
    "print(\"Status:\", response[\"status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"id\": \"ftjob-4Mz8NsADmeBwZSdZni2G7C7L\",\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"created_at\": 1694530716,\n",
      "  \"finished_at\": null,\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"organization_id\": \"org-paNJzG7NBclkFaxfxYM9IntQ\",\n",
      "  \"result_files\": [],\n",
      "  \"status\": \"running\",\n",
      "  \"validation_file\": \"file-IEfGb36xxasnBW1bLE8vRKzz\",\n",
      "  \"training_file\": \"file-vXIsNXTblmxC5tSVLHVdS8Gl\",\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": 3\n",
      "  },\n",
      "  \"trained_tokens\": null,\n",
      "  \"error\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = openai.FineTuningJob.retrieve(job_id)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500/2295: training loss=1.73\n",
      "Step 600/2295: training loss=0.78\n",
      "Step 700/2295: training loss=2.18\n",
      "Step 800/2295: training loss=1.91\n",
      "Step 900/2295: training loss=1.74\n",
      "Step 1000/2295: training loss=2.04\n",
      "Step 1100/2295: training loss=0.19\n",
      "Step 1200/2295: training loss=1.91\n",
      "Step 1300/2295: training loss=1.87\n",
      "Step 1400/2295: training loss=1.88\n",
      "Step 1500/2295: training loss=1.95\n",
      "Step 1600/2295: training loss=1.93\n",
      "Step 1700/2295: training loss=1.99\n",
      "Step 1800/2295: training loss=1.85\n",
      "Step 1900/2295: training loss=0.39\n",
      "Step 2000/2295: training loss=0.23\n",
      "Step 2100/2295: training loss=2.81\n",
      "Step 2200/2295: training loss=2.11\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0613:dq-data:counselor-test2:7y0ExFEB\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = openai.FineTuningJob.list_events(id=job_id)\n",
    "\n",
    "events = response[\"data\"]\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event[\"message\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned model ID: ft:gpt-3.5-turbo-0613:dq-data:counselor-test2:7y0ExFEB\n"
     ]
    }
   ],
   "source": [
    "response = openai.FineTuningJob.retrieve(job_id)\n",
    "fine_tuned_model_id = response[\"fine_tuned_model\"]\n",
    "\n",
    "print(\"Fine-tuned model ID:\", fine_tuned_model_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
